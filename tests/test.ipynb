{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "194a6f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from zoneinfo import ZoneInfo\n",
    "from google.adk.agents import Agent, SequentialAgent\n",
    "from google.adk.models.lite_llm import LiteLlm\n",
    "from google.adk.tools import google_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f12206d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AGENT_MODEL = \"ollama/gemma3\"\n",
    "# AGENT_MODEL = \"openai/gpt-5-nano\"\n",
    "AGENT_MODEL = \"gemini-2.5-flash\"\n",
    "\n",
    "\n",
    "def get_weather(city: str) -> dict:\n",
    "    \"\"\"Retrieves the current weather report for a specified city.\n",
    "\n",
    "    Args:\n",
    "        city (str): The name of the city (e.g., \"New York\", \"London\", \"Tokyo\").\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the weather information.\n",
    "              Includes a 'status' key ('success' or 'error').\n",
    "              If 'success', includes a 'report' key with weather details.\n",
    "              If 'error', includes an 'error_message' key.\n",
    "    \"\"\"\n",
    "    print(f\"--- Tool: get_weather called for city: {city} ---\")  # Log tool execution\n",
    "    city_normalized = city.lower().replace(\" \", \"\")  # Basic normalization\n",
    "\n",
    "    # Mock weather data\n",
    "    # api call\n",
    "    mock_weather_db = {\n",
    "        \"newyork\": {\n",
    "            \"status\": \"success\",\n",
    "            \"report\": \"The weather in New York is sunny with a temperature of 25°C.\",\n",
    "        },\n",
    "        \"london\": {\n",
    "            \"status\": \"success\",\n",
    "            \"report\": \"It's cloudy in London with a temperature of 15°C.\",\n",
    "        },\n",
    "        \"tokyo\": {\n",
    "            \"status\": \"success\",\n",
    "            \"report\": \"Tokyo is experiencing light rain and a temperature of 18°C.\",\n",
    "        },\n",
    "        \"paris\": {\n",
    "            \"status\": \"success\",\n",
    "            \"report\": \"The weather in Paris is sunny with a temperature of 22°C.\",\n",
    "        },\n",
    "    }\n",
    "\n",
    "    if city_normalized in mock_weather_db:\n",
    "        return mock_weather_db[city_normalized]\n",
    "    else:\n",
    "        return {\n",
    "            \"status\": \"error\",\n",
    "            \"error_message\": f\"Sorry, I don't have weather information for '{city}'.\",\n",
    "        }\n",
    "\n",
    "\n",
    "def get_current_time(city: str) -> dict:\n",
    "    \"\"\"Returns the current time in a specified city.\n",
    "\n",
    "    Args:\n",
    "        city (str): The name of the city for which to retrieve the current time.\n",
    "\n",
    "    Returns:\n",
    "        dict: status and result or error msg.\n",
    "    \"\"\"\n",
    "\n",
    "    if city.lower() == \"new york\":\n",
    "        tz_identifier = \"America/New_York\"\n",
    "    else:\n",
    "        return {\n",
    "            \"status\": \"error\",\n",
    "            \"error_message\": (f\"Sorry, I don't have timezone information for {city}.\"),\n",
    "        }\n",
    "\n",
    "    tz = ZoneInfo(tz_identifier)\n",
    "    now = datetime.datetime.now(tz)\n",
    "    report = f'The current time in {city} is {now.strftime(\"%Y-%m-%d %H:%M:%S %Z%z\")}'\n",
    "    return {\"status\": \"success\", \"report\": report}\n",
    "\n",
    "\n",
    "# -- Sequential Agent ---\n",
    "# Destination Research Agent - Researches location information\n",
    "destination_research_agent = Agent(\n",
    "    name=\"DestinationResearchAgent\",\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    tools=[google_search],\n",
    "    description=\"An agent that researches travel destinations and gathers essential information\",\n",
    "    instruction=\"\"\"\n",
    "    You are a travel researcher. You will be given a destination and travel preferences, and you will research:\n",
    "    - Best time to visit and weather patterns\n",
    "    - Top attractions and must-see locations\n",
    "    - Local culture, customs, and etiquette tips\n",
    "    - Transportation options within the destination\n",
    "    - Safety considerations and travel requirements\n",
    "    Provide comprehensive destination insights for trip planning.\n",
    "    \"\"\",\n",
    "    output_key=\"destination_research\",\n",
    ")\n",
    "\n",
    "\n",
    "# Itinerary Builder Agent - Creates detailed travel schedule\n",
    "itinerary_builder_agent = Agent(\n",
    "    model=AGENT_MODEL,\n",
    "    name=\"ItineraryBuilderAgent\",\n",
    "    description=\"An agent that creates structured travel itineraries with daily schedules\",\n",
    "    instruction=\"\"\"\n",
    "    You are a professional travel planner. Using the research from \"destination_research\" output, create a detailed itinerary that includes:\n",
    "    - Day-by-day schedule with recommended activities\n",
    "    - Suggested accommodation areas or districts\n",
    "    - Estimated time requirements for each activity\n",
    "    - Meal recommendations and dining suggestions\n",
    "    - Budget estimates for major expenses\n",
    "    Structure it logically for easy following during the trip.\n",
    "    \"\"\",\n",
    "    output_key=\"travel_itinerary\",\n",
    ")\n",
    "\n",
    "# Travel Optimizer Agent - Adds practical tips and optimizations\n",
    "travel_optimizer_agent = Agent(\n",
    "    model=AGENT_MODEL,\n",
    "    name=\"TravelOptimizerAgent\",\n",
    "    description=\"An agent that optimizes travel plans with practical advice and alternatives\",\n",
    "    instruction=\"\"\"\n",
    "    You are a seasoned travel consultant. Using the itinerary from \"travel_itinerary\" output, optimize it by adding:\n",
    "    - Money-saving tips and budget alternatives\n",
    "    - Packing recommendations specific to the destination\n",
    "    - Backup plans for weather or unexpected situations\n",
    "    - Local apps, websites, or resources to download\n",
    "    - Cultural do's and don'ts for respectful travel\n",
    "    \n",
    "    Format the final output as:\n",
    "    \n",
    "    ITINERARY: {travel_itinerary}\n",
    "    \n",
    "    OPTIMIZATION TIPS: [your money-saving and practical tips here]\n",
    "    \n",
    "    TRAVEL ESSENTIALS: [packing and preparation advice here]\n",
    "    \n",
    "    BACKUP PLANS: [alternative options and contingencies here]\n",
    "    \"\"\",\n",
    ")\n",
    "\n",
    "root_agent = SequentialAgent(\n",
    "    name=\"TravelPlanningSystem\",\n",
    "    # model=LiteLlm(AGENT_MODEL),#not needed for SequentialAgent\n",
    "    # model=AGENT_MODEL, #not needed for SequentialAgent\n",
    "    description=\"A comprehensive system that researches destinations, builds itineraries, and optimizes travel plans\",\n",
    "    sub_agents=[\n",
    "        destination_research_agent,\n",
    "        itinerary_builder_agent,\n",
    "        travel_optimizer_agent,\n",
    "    ],\n",
    "    # instruction=\"You are a travel planner agent. Help the user plan their trip.\",\n",
    "    # tools=[get_weather, get_current_time],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdade74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5611929f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61eb0f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = 'agent'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c5b26d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wsk2000\\Documents\\Github_codes\\personal_assistant\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "# Load environment variables (works in both notebooks and scripts)\n",
    "env_path = Path.cwd() / \".env\"  # Use current working directory instead of __file__\n",
    "if env_path.exists():\n",
    "    load_dotenv(dotenv_path=str(env_path), override=True)\n",
    "else:\n",
    "    # Try parent directory if .env is not in current directory\n",
    "    env_path = Path.cwd().parent / \".env\"\n",
    "    if env_path.exists():\n",
    "        load_dotenv(dotenv_path=str(env_path), override=True)\n",
    "    else:\n",
    "        # Fallback: just load from current directory\n",
    "        load_dotenv(override=False)\n",
    "\n",
    "\n",
    "def generate_prompt_with_gemini(\n",
    "    user_input: str,\n",
    "    model: str = \"gemini-2.5-flash\",\n",
    "    temperature: float = 0.7,\n",
    "    max_output_tokens: Optional[int] = None,\n",
    "    system_instruction: Optional[str] = None,\n",
    "    project_id: Optional[str] = None,\n",
    "    location: str = \"us-central1\"\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Generate a prompt or text response using Google's Gemini model via Vertex AI.\n",
    "    \n",
    "    Args:\n",
    "        user_input (str): The input prompt or question to send to Gemini\n",
    "        model (str): The Gemini model to use (default: \"gemini-2.0-flash\")\n",
    "                    Options: \"gemini-2.0-flash\", \"gemini-1.5-flash\", \"gemini-1.5-pro\", etc.\n",
    "                    Note: Vertex AI model names typically end with \"-001\" (e.g., \"gemini-2.0-flash-001\")\n",
    "        temperature (float): Controls randomness (0.0-1.0). Higher = more creative (default: 0.7)\n",
    "        max_output_tokens (Optional[int]): Maximum tokens in response (None = model default)\n",
    "        system_instruction (Optional[str]): Optional system instruction to set the model's behavior\n",
    "        project_id (Optional[str]): Google Cloud project ID. If None, uses GOOGLE_CLOUD_PROJECT env var\n",
    "        location (str): Google Cloud location/region (default: \"us-central1\")\n",
    "    \n",
    "    Returns:\n",
    "        str: The generated text response from Gemini\n",
    "    \n",
    "    Example:\n",
    "        >>> response = generate_prompt_with_gemini(\"Create a travel itinerary for Tokyo\")\n",
    "        >>> print(response)\n",
    "    \"\"\"\n",
    "    # Get API key from environment\n",
    "    google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "    if not google_api_key:\n",
    "        raise ValueError(\"GOOGLE_API_KEY not found in environment variables\")\n",
    "    \n",
    "    # Configure the API\n",
    "    genai.configure(api_key=google_api_key)\n",
    "    \n",
    "    # Configure generation parameters\n",
    "    generation_config = {\n",
    "        \"temperature\": temperature,\n",
    "    }\n",
    "    if max_output_tokens:\n",
    "        generation_config[\"max_output_tokens\"] = max_output_tokens\n",
    "    \n",
    "    # Initialize the model\n",
    "    model_instance = genai.GenerativeModel(\n",
    "        model_name=model,\n",
    "        system_instruction=system_instruction,\n",
    "        generation_config=generation_config\n",
    "    )\n",
    "    \n",
    "    # Generate response\n",
    "    response = model_instance.generate_content(user_input)\n",
    "    \n",
    "    # Extract text from the response\n",
    "    return response.text\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76d7c2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "style_instructions = {\n",
    "        \"general\": \"You are a helpful assistant.\",\n",
    "        \"creative\": \"You are a creative writer. Be imaginative and engaging.\",\n",
    "        \"technical\": \"You are a technical expert. Be precise and detailed.\",\n",
    "        \"concise\": \"You are a concise assistant. Be brief and to the point.\"\n",
    "    }\n",
    "    \n",
    "system_instruction = style_instructions[\"general\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1518fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_prompt = 'what is the capital of the moon?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b28ed7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = generate_prompt_with_gemini(\n",
    "        full_prompt,\n",
    "        system_instruction=system_instruction,\n",
    "        model=\"gemini-2.5-flash\",  \n",
    "        project_id=project_id\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "047b7c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The Moon does not have a capital.\\n\\nIt's not a country or a political entity, so it doesn't have cities, governments, or anything like that.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8d8deb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f392aa97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3a3953a",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_CLOUD_PROJECT = 'agent'\n",
    "project_id = 'gen-lang-client-0288149151'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de2e5958",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c9b1459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_bigquery_query(\n",
    "    project_id: Optional[str] = GOOGLE_CLOUD_PROJECT\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Execute a BigQuery SQL query and return results as a pandas DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The SQL query to execute\n",
    "        project_id (Optional[str]): Google Cloud project ID. If None, uses GOOGLE_CLOUD_PROJECT env var or default credentials\n",
    "        use_legacy_sql (bool): Whether to use legacy SQL syntax (default: False, uses standard SQL)\n",
    "        max_results (Optional[int]): Maximum number of rows to return (None = return all)\n",
    "        return_dataframe (bool): If True, returns pandas DataFrame; if False, returns raw query job result\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Query results as a pandas DataFrame\n",
    "    \n",
    "    Example:\n",
    "        >>> df = run_bigquery_query(\n",
    "        ...     \"SELECT name, age FROM `my-project.my_dataset.my_table` LIMIT 10\",\n",
    "        ...     project_id=\"my-project\"\n",
    "        ... )\n",
    "        >>> print(df.head())\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize BigQuery client\n",
    "    client = bigquery.Client(project=project_id)\n",
    "    \n",
    "    # Configure query job\n",
    "    job_config = bigquery.QueryJobConfig()\n",
    "    \n",
    "    # Execute query\n",
    "    try:\n",
    "        query = \"\"\"\n",
    "         SELECT * FROM `gen-lang-client-0288149151.personal_assistant.meal_hour`\n",
    "         \"\"\"\n",
    "        query_job = client.query(query, job_config=job_config)\n",
    "        \n",
    "        # Wait for the query to complete\n",
    "        query_job.result()\n",
    "        \n",
    "        # Check for errors\n",
    "        if query_job.errors:\n",
    "            raise Exception(f\"Query failed with errors: {query_job.errors}\")\n",
    "        \n",
    "        # Get results\n",
    "        results = query_job.to_dataframe()\n",
    "\n",
    "        return results\n",
    "    \n",
    "\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error executing BigQuery query: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbe67a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = run_bigquery_query(\n",
    "    project_id=project_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "402d15b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>current_time</th>\n",
       "      <th>current_time_plus_8h</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-12-30 10:00:00</td>\n",
       "      <td>2025-12-30 18:00:00</td>\n",
       "      <td>first meal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          current_time current_time_plus_8h       notes\n",
       "0  2025-12-30 10:00:00  2025-12-30 18:00:00  first meal"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc2eed64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def record_time_with_notes(notes: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Records the current time, current time plus 8 hours, and a notes field.\n",
    "    Returns a pandas DataFrame with a single row.\n",
    "    \n",
    "    Args:\n",
    "        notes (str): Notes to record.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with columns ['current_time', 'current_time_plus_8h', 'notes']\n",
    "    \"\"\"\n",
    "    now = datetime.now()\n",
    "    plus_8h = now + timedelta(hours=8)\n",
    "    fmt = \"%Y-%m-%d %H:%M:%S\"\n",
    "    data = {\n",
    "        \"current_time\": [now.strftime(fmt)],\n",
    "        \"current_time_plus_8h\": [plus_8h.strftime(fmt)],\n",
    "        \"notes\": [notes]\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Example usage:\n",
    "df = record_time_with_notes(\"Meeting with AI at 10am\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b17c087e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>current_time</th>\n",
       "      <th>current_time_plus_8h</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-12-30 15:29:06</td>\n",
       "      <td>2025-12-30 23:29:06</td>\n",
       "      <td>Meeting with AI at 10am</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          current_time current_time_plus_8h                    notes\n",
       "0  2025-12-30 15:29:06  2025-12-30 23:29:06  Meeting with AI at 10am"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5c18946",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_df_to_bq(df, project_id=\"gen-lang-client-0288149151\"):\n",
    "    \"\"\"\n",
    "    Saves the given DataFrame to the BigQuery table:\n",
    "    gen-lang-client-0288149151.personal_assistant.meal_hour\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The dataframe to save.\n",
    "        project_id (str): The GCP project id (default is 'gen-lang-client-0288149151').\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    table_id = f\"{project_id}.personal_assistant.meal_hour\"\n",
    "    # 'if_exists=append' appends rows to the table if it exists.\n",
    "    # Requires: pip install pandas-gbq\n",
    "    df.to_gbq(\n",
    "        destination_table=table_id,\n",
    "        project_id=project_id,\n",
    "        if_exists=\"append\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93068aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nx/cc5m85l51273yhvdw6fnwkjm0000gn/T/ipykernel_22983/473704780.py:16: FutureWarning: to_gbq is deprecated and will be removed in a future version. Please use pandas_gbq.to_gbq instead: https://pandas-gbq.readthedocs.io/en/latest/api.html#pandas_gbq.to_gbq\n",
      "  df.to_gbq(\n",
      "100%|██████████| 1/1 [00:00<00:00, 5047.30it/s]\n"
     ]
    }
   ],
   "source": [
    "save_df_to_bq(df, project_id=\"gen-lang-client-0288149151\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021e3288",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38b61d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "954d03d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_description=\"The image displays a product information sheet and nutrition label for 'Spicy Celtuce' (香辣莴笋), which is a type of pickled vegetable. It includes a picture of the sliced green vegetable seasoned with chili flakes. According to the nutrition facts table, the product contains 204 kJ of energy per 100g, along with 1.5g of protein, 1.8g of fat, 6.6g of carbohydrates, and 1338mg of sodium.\" calorie_intake=49\n",
      "Calories: 49\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# Define your Pydantic model\n",
    "class FoodAnalysis(BaseModel):\n",
    "    image_description: str\n",
    "    calorie_intake: int\n",
    "\n",
    "client = genai.Client(\n",
    "    vertexai=True, \n",
    "    project=\"gen-lang-client-0288149151\", \n",
    "    location=\"global\",\n",
    ")\n",
    "\n",
    "IMAGE_URI = 'gs://personal_assistant_agent/latiao.png'\n",
    "model = \"gemini-3-flash-preview\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=model,\n",
    "    contents=[\n",
    "        \"What is shown in this image? What is estimated calorie intake?\",\n",
    "        types.Part.from_uri(\n",
    "            file_uri=IMAGE_URI,\n",
    "            mime_type=\"image/png\",\n",
    "        ),\n",
    "    ],\n",
    "    config=types.GenerateContentConfig(\n",
    "        response_mime_type=\"application/json\",\n",
    "        response_schema=FoodAnalysis,  # Pass the Pydantic model\n",
    "    )\n",
    ")\n",
    "\n",
    "# Parse directly into your model\n",
    "result = FoodAnalysis.model_validate_json(response.text)\n",
    "print(result)\n",
    "print(f\"Calories: {result.calorie_intake}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f8f7d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.calorie_intake"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
